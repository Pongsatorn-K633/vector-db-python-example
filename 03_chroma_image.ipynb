{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "882148c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os, uuid\n",
    "from typing import List\n",
    "from PIL import Image\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e44120df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Config ----------------\n",
    "PERSIST_DIR = \"./chroma_multimodal_local\"\n",
    "COLLECTION_NAME = \"pets_local\"\n",
    "\n",
    "DOG_IMAGES = [\"images/dog1.png\", \"images/dog2.png\", \"images/dog3.png\"]\n",
    "CAT_IMAGES = [\"images/cat1.png\", \"images/cat2.png\", \"images/cat3.png\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0a73953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Helpers ----------------\n",
    "def l2_normalize(vecs: np.ndarray) -> np.ndarray:\n",
    "  norms = np.linalg.norm(vecs, axis=1, keepdims=True) + 1e-12\n",
    "  return vecs / norms\n",
    "\n",
    "def load_images(paths: List[str]) -> List[Image.Image]:\n",
    "  \"\"\"โหลดรูปจาก path ที่ให้มา\"\"\"\n",
    "  return [Image.open(path).convert(\"RGB\") for path in paths]\n",
    "\n",
    "def encode_images(model: SentenceTransformer, images: List[Image.Image]) -> np.ndarray:\n",
    "  \"\"\"แปลงรูปเป็น embedding แล้ว normalize\"\"\"\n",
    "  embs = model.encode(images, convert_to_numpy=True, batch_size=4, normalize_embeddings=False)\n",
    "  return l2_normalize(embs)\n",
    "\n",
    "def add_images_to_db(collection, images: List[str], labels: List[str], embs: np.ndarray):\n",
    "    \"\"\"เพิ่มรูปและ metadata เข้า Chroma\"\"\"\n",
    "    doc_ids = [str(uuid.uuid4()) for _ in images]\n",
    "    metadatas = [{\"label\": lbl, \"filename\": os.path.basename(path)} for lbl, path in zip(labels, images)]\n",
    "    documents = [f\"A {lbl} image ({os.path.basename(path)})\" for lbl, path in zip(labels, images)]\n",
    "\n",
    "    collection.add(\n",
    "        ids=doc_ids,\n",
    "        embeddings=embs.tolist(),\n",
    "        metadatas=metadatas,\n",
    "        documents=documents\n",
    "    )\n",
    "    print(f\"Indexed {len(doc_ids)} images into collection '{collection.name}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ababc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 1 - เตรียม path ของรูป\n",
    "all_images = DOG_IMAGES + CAT_IMAGES\n",
    "labels = [\"dog\"] * len(DOG_IMAGES) + [\"cat\"] * len(CAT_IMAGES)\n",
    "\n",
    "# Step 2 - โหลด CLIP model\n",
    "model = SentenceTransformer(\"clip-ViT-B-32\")\n",
    "\n",
    "# Step 3 - โหลดรูปจาก local\n",
    "pil_images = load_images(all_images)\n",
    "\n",
    "# Step 4 - embedding\n",
    "img_embs = encode_images(model, pil_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c3fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 - Setup Chroma\n",
    "client = chromadb.Client(chromadb.config.Settings(persist_directory=PERSIST_DIR))\n",
    "collection = client.get_or_create_collection(name=COLLECTION_NAME,  metadata={\"hnsw:space\": \"cosine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25cb826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 6 images into collection 'pets_local'.\n"
     ]
    }
   ],
   "source": [
    "# Step 6 - เพิ่มรูปเข้า DB\n",
    "add_images_to_db(collection, all_images, labels, img_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f62bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Query: dog ===\n",
      "#1 -> dog3.png (dog) distance=0.7287\n",
      "desc: A dog image (dog3.png)\n",
      "#2 -> dog2.png (dog) distance=0.7348\n",
      "desc: A dog image (dog2.png)\n",
      "#3 -> dog1.png (dog) distance=0.7422\n",
      "desc: A dog image (dog1.png)\n",
      "#4 -> cat1.png (cat) distance=0.7719\n",
      "desc: A cat image (cat1.png)\n"
     ]
    }
   ],
   "source": [
    "# Step 7 - ทดสอบ Query\n",
    "query = \"dog\"\n",
    "q_emb = model.encode([query], convert_to_numpy=True)\n",
    "q_emb = l2_normalize(q_emb)\n",
    "\n",
    "res = collection.query(\n",
    "  query_embeddings=q_emb.tolist(),\n",
    "  n_results=4,\n",
    "  include=[\"metadatas\", \"documents\", \"distances\"]\n",
    ")\n",
    "\n",
    "print(f\"\\n=== Query: {query} ===\")\n",
    "for rank, (meta, doc, dist) in enumerate(zip(res[\"metadatas\"][0], res[\"documents\"][0], res[\"distances\"][0]), start=1):\n",
    "  print(f\"#{rank} -> {meta['filename']} ({meta['label']}) distance={dist:.4f}\")\n",
    "  print(\"desc:\", doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
